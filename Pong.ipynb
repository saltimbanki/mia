{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm3E_qtVowiv"
      },
      "source": [
        "# Aprendizaje por Refuerzo: el Pong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbZtefR3owix"
      },
      "source": [
        "El artículo completo en el blog [Aprende Machine Learning](http://www.aprendemachinelearning.com) en Español.\n",
        "\n",
        "Crearemos el juego del pong con interface gráfica de Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJR207reowix"
      },
      "source": [
        "El Agente deberá aprender a jugar sólo mediante premios y castigos.\n",
        "\n",
        "Crearemos las clases:\n",
        "\n",
        "* Agente: implementará el algoritmo de QLearning\n",
        "* Environment: será nuestro tablero de juego\n",
        "\n",
        "Y crearemos una función para comenzar a jugar, donde entrenará iterando miles de partidas de pong.\n",
        "\n",
        "Finalmente, ejecutarmos 1 partida con el agente ya entrenado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-27T10:21:01.578976Z",
          "start_time": "2020-12-27T10:20:58.063893Z"
        },
        "id": "_qVREacfowiy"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------------------------\n",
        "#   INSTALAMOS LIBRERÍAS\n",
        "#-----------------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "from math import ceil,floor\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P1Ha8F-owiz"
      },
      "source": [
        "# Clase Agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-27T10:22:24.177788Z",
          "start_time": "2020-12-27T10:22:24.158177Z"
        },
        "id": "rY1s3NEpowiz"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------------------------\n",
        "#   CREAMOS LA CLASE AGENTE - IMPLEMENTARÁ EL ALGORITMO DE QLEARNING\n",
        "#-----------------------------------------------------------------------------\n",
        "class PongAgent:\n",
        "\n",
        "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
        "\n",
        "        # Creamos la tabla de politicas\n",
        "        if policy is not None:\n",
        "            self._q_table = policy\n",
        "        else:\n",
        "            position = list(game.positions_space.shape)\n",
        "            position.append(len(game.action_space))\n",
        "            self._q_table = np.zeros(position)\n",
        "\n",
        "        self.discount_factor = discount_factor\n",
        "        self.learning_rate = learning_rate\n",
        "        self.ratio_explotacion = ratio_explotacion\n",
        "\n",
        "    def get_next_step(self, state, game):\n",
        "\n",
        "        # Damos un paso aleatorio...\n",
        "        next_step = np.random.choice(list(game.action_space))\n",
        "\n",
        "        # o tomaremos el mejor paso...\n",
        "        if np.random.uniform() <= self.ratio_explotacion:\n",
        "            # tomar el maximo\n",
        "            idx_action = np.random.choice(np.flatnonzero(\n",
        "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
        "                ))\n",
        "            next_step = list(game.action_space)[idx_action]\n",
        "\n",
        "        return next_step\n",
        "\n",
        "    #-----------------------------------------------------------------------------\n",
        "    # Actualizamos las politicas con las recompensas obtenidas\n",
        "    #-----------------------------------------------------------------------------\n",
        "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
        "        idx_action_taken =list(game.action_space).index(action_taken)\n",
        "\n",
        "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
        "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
        "\n",
        "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
        "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
        "        if reached_end:\n",
        "            future_max_q_value = reward_action_taken #maximum reward\n",
        "\n",
        "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
        "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
        "\n",
        "    def print_policy(self):\n",
        "        for row in np.round(self._q_table,1):\n",
        "            for column in row:\n",
        "                print('[', end='')\n",
        "                for value in column:\n",
        "                    print(str(value).zfill(5), end=' ')\n",
        "                print('] ', end='')\n",
        "            print('')\n",
        "\n",
        "    def get_policy(self):\n",
        "        return self._q_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arJGowBcowiz"
      },
      "source": [
        "# Clase Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-27T10:22:39.529477Z",
          "start_time": "2020-12-27T10:22:39.493343Z"
        },
        "id": "6eEJ1_dWowi0"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------------------------\n",
        "#   CREAMOS LA CLASE ENTORNO\n",
        "#-----------------------------------------------------------------------------\n",
        "class PongEnvironment:\n",
        "\n",
        "    def __init__(self, max_life = 3, height_px = 40*2, width_px = 50*2, movimiento_px = 3):\n",
        "\n",
        "        #-----------------------------------------------------------------------------\n",
        "        # Acciones que se desarrollarán\n",
        "        #-----------------------------------------------------------------------------\n",
        "        self.action_space = [ 'Arriba','Abajo' ]\n",
        "\n",
        "\n",
        "        self._step_penalization = 0\n",
        "\n",
        "        self.state = [0,0,0]\n",
        "\n",
        "        self.total_reward = 0\n",
        "\n",
        "        self.dx = movimiento_px\n",
        "        self.dy = movimiento_px\n",
        "\n",
        "        filas = ceil(height_px/movimiento_px)\n",
        "        columnas = ceil(width_px/movimiento_px)\n",
        "\n",
        "        self.positions_space = np.array([[[0 for z in range(columnas)]\n",
        "                                                  for y in range(filas)]\n",
        "                                                     for x in range(filas)])\n",
        "\n",
        "        self.lives = max_life\n",
        "        self.max_life=max_life\n",
        "\n",
        "        self.x = randint(int(width_px/2), width_px)\n",
        "        self.y = randint(0, height_px-10)\n",
        "\n",
        "        self.player_alto = int(height_px/4)\n",
        "\n",
        "        self.player1 = self.player_alto  # posic. inicial del player\n",
        "\n",
        "        self.score = 0\n",
        "\n",
        "        self.width_px = width_px\n",
        "        self.height_px = height_px\n",
        "        self.radio = 2.5\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_reward = 0\n",
        "        self.state = [0,0,0]\n",
        "        self.lives = self.max_life\n",
        "        self.score = 0\n",
        "        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "        self.y = randint(0, self.height_px-10)\n",
        "        return self.state\n",
        "\n",
        "    #-----------------------------------------------------------------------------\n",
        "    # La recompensa se determina en función del estado del juego y de las acciones tomadas por el agente.\n",
        "    #-----------------------------------------------------------------------------\n",
        "    def step(self, action, animate=False):\n",
        "        self._apply_action(action, animate)\n",
        "        done = self.lives <=0 # final\n",
        "        reward = self.score\n",
        "        reward += self._step_penalization\n",
        "        self.total_reward += reward\n",
        "        return self.state, reward , done\n",
        "\n",
        "    def _apply_action(self, action, animate=False):\n",
        "\n",
        "        if action == \"Arriba\":\n",
        "            self.player1 += abs(self.dy)\n",
        "        elif action == \"Abajo\":\n",
        "            self.player1 -= abs(self.dy)\n",
        "\n",
        "        self.avanza_player()\n",
        "\n",
        "        self.avanza_frame()\n",
        "\n",
        "        if animate:\n",
        "            clear_output(wait=True);\n",
        "            fig = self.dibujar_frame()\n",
        "            plt.show()\n",
        "\n",
        "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
        "\n",
        "    def detectaColision(self, ball_y, player_y):\n",
        "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def avanza_player(self):\n",
        "        if self.player1 + self.player_alto >= self.height_px:\n",
        "            self.player1 = self.height_px - self.player_alto\n",
        "        elif self.player1 <= -abs(self.dy):\n",
        "            self.player1 = -abs(self.dy)\n",
        "\n",
        "    def avanza_frame(self):\n",
        "        self.x += self.dx\n",
        "        self.y += self.dy\n",
        "        if self.x <= 3 or self.x > self.width_px:\n",
        "            self.dx = -self.dx\n",
        "            if self.x <= 3:\n",
        "                ret = self.detectaColision(self.y, self.player1)\n",
        "\n",
        "                if ret:\n",
        "                    self.score = 10\n",
        "                else:\n",
        "                    self.score = -10\n",
        "                    self.lives -= 1\n",
        "                    if self.lives>0:\n",
        "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
        "                        self.y = randint(0, self.height_px-10)\n",
        "                        self.dx = abs(self.dx)\n",
        "                        self.dy = abs(self.dy)\n",
        "        else:\n",
        "            self.score = 0\n",
        "\n",
        "        if self.y < 0 or self.y > self.height_px:\n",
        "            self.dy = -self.dy\n",
        "\n",
        "    def dibujar_frame(self):\n",
        "        fig = plt.figure(figsize=(5, 4))\n",
        "        a1 = plt.gca()\n",
        "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
        "        a1.set_ylim(-5, self.height_px+5)\n",
        "        a1.set_xlim(-5, self.width_px+5)\n",
        "\n",
        "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
        "        a1.add_patch(circle);\n",
        "        a1.add_patch(rectangle)\n",
        "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
        "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
        "        if self.lives <=0:\n",
        "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
        "        elif self.total_reward >= 1000:\n",
        "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
        "        return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O50g4qfKowi0"
      },
      "source": [
        "# Juego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-27T10:22:51.265359Z",
          "start_time": "2020-12-27T10:22:51.249319Z"
        },
        "id": "5FKfBQk4owi0"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------------------------\n",
        "#   Entrena al Agente y juega al Pong durante una serie de rondas\n",
        "#-----------------------------------------------------------------------------\n",
        "def play( rounds = 5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
        "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
        "\n",
        "    if game is None:\n",
        "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
        "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
        "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
        "\n",
        "    if learner is None:\n",
        "        try:\n",
        "            q_table = np.load( \"q_table.npy\" )  # Cargar la tabla Q aprendida desde el archivo\n",
        "            print( \"Cargando la Q-table\" )\n",
        "            learner = PongAgent(game, policy=q_table, discount_factor=discount_factor, learning_rate=learning_rate, ratio_explotacion=ratio_explotacion)\n",
        "        except FileNotFoundError:\n",
        "            print(\"Creando una nueva Q-table\")\n",
        "            learner = PongAgent(game, discount_factor=discount_factor, learning_rate=learning_rate, ratio_explotacion=ratio_explotacion)\n",
        "\n",
        "\n",
        "    max_points= -9999\n",
        "    first_max_reached = 0\n",
        "    total_rw = 0\n",
        "    steps=[]\n",
        "\n",
        "    for played_games in range(0, rounds):\n",
        "        state = game.reset()\n",
        "        reward, done = None, None\n",
        "\n",
        "        itera=0\n",
        "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
        "            old_state = np.array(state)\n",
        "            next_action = learner.get_next_step(state, game)\n",
        "            state, reward, done = game.step(next_action, animate=animate)\n",
        "            if rounds > 1:\n",
        "                learner.update(game, old_state, next_action, reward, state, done)\n",
        "            itera+=1\n",
        "\n",
        "        steps.append(itera)\n",
        "\n",
        "        total_rw+=game.total_reward\n",
        "        if game.total_reward > max_points:\n",
        "            max_points=game.total_reward\n",
        "            first_max_reached = played_games\n",
        "\n",
        "        if played_games %500==0 and played_games >1 and not animate:\n",
        "            print(\"-- Partidas[\", played_games,  \"] Max Score[\", max_points,\"]\")\n",
        "\n",
        "    if played_games>1:\n",
        "        print('Partidas[',played_games,'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
        "\n",
        "    # Guardar la tabla Q aprendida en archivo\n",
        "    np.save( \"q_table.npy\", learner.get_policy() )\n",
        "    print( \"Grabando la Q-table\" )\n",
        "\n",
        "    return learner, game\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-27T10:24:06.516334Z",
          "start_time": "2020-12-27T10:22:51.808220Z"
        },
        "id": "Wmdhn-noowi1"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------------------------------------\n",
        "# Este bucle es de entrenamiento\n",
        "#----------------------------------------------------------------------------\n",
        "fin_bucle = False\n",
        "while( fin_bucle != True ):\n",
        "    learner, game = play( rounds = 500, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion = 0.85 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-27T10:35:16.554658Z",
          "start_time": "2020-12-27T10:25:44.533659Z"
        },
        "id": "t4hHJtQFowi1"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------------------------\n",
        "# Este bucle es de juego del ordenador en función del aprendizaje desarrollado\n",
        "#-----------------------------------------------------------------------------\n",
        "learner2 = PongAgent( game, policy = learner.get_policy() )\n",
        "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
        "player = play ( rounds = 1, learner = learner2, game = game, animate = True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1UjGbPeowi1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH7YdafGowi1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w9eSN07owi1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tm3E_qtVowiv",
        "5P1Ha8F-owiz",
        "arJGowBcowiz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}